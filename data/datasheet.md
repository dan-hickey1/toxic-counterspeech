# Datasheet for datasets from "Assessing the Toxicity and Effects of Counterspeech on Reddit"

Questions from the [Datasheets for Datasets](https://arxiv.org/abs/1803.09010) paper, v7.

Jump to section:

- [Motivation](#motivation)
- [Composition](#composition)
- [Collection process](#collection-process)
- [Preprocessing/cleaning/labeling](#preprocessingcleaninglabeling)
- [Uses](#uses)
- [Distribution](#distribution)
- [Maintenance](#maintenance)

## Motivation

_The questions in this section are primarily intended to encourage dataset creators
to clearly articulate their reasons for creating the dataset and to promote transparency
about funding interests._

### For what purpose was the dataset created? 

These datasets were used to train/fine-tune language models for counterspeech/hate speech detection, as well as data representing hate subreddits and their matched non-hate counterparts.

### Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)?
(Omitted for anonymity.)

### Who funded the creation of the dataset? 
(Omitted for anonymity.)

### Any other comments?

## Composition

_Most of these questions are intended to provide dataset consumers with the
information they need to make informed decisions about using the dataset for
specific tasks. The answers to some of these questions reveal information
about compliance with the EU’s General Data Protection Regulation (GDPR) or
comparable regulations in other jurisdictions._

### What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)?

The files `validation_set.csv` and `gpt_4o_labels.csv` each have instances representing pairs of comments in hate subreddits (newcomer comments and their replies). The `matched_treatment_and_control_subreddits.csv` file has instances representing hate subreddits matched to their non-hate counterparts. The file `subreddits_max_timestamps.csv` has instances representing hate subreddits and the last timestamp from each subreddit.

### How many instances are there in total (of each type, if appropriate)?

The `validation_set.csv` file contains 672 instances, the `gpt_4o_labels.csv` file contains 5,560 instances, and the `matched_treatment_and_control_subreddits.csv` and `subreddits_max_timestamps.csv` files contain 168 instances each.

### Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set?
The subreddit-level data contains all possible instances obtained from (Hickey et al.'s)[https://ojs.aaai.org/index.php/ICWSM/article/view/35846] dataset of hate subreddits. The training and validation datasets contain random samples of newcomer-reply pairs from each of those subreddits.

### What data does each instance consist of? 
Each instance consists of lightly processed text from Reddit comments, as well as the Reddit IDs of the newcomer comments.

### Is there a label or target associated with each instance?
For each instance, there is a label describing whether the newcomer or reply contains counterspeech, hate speech, or other speech.

### Is any information missing from individual instances?
No.

### Are relationships between individual instances made explicit (e.g., users’ movie ratings, social network links)?
There is no data directly describing relationships among rows of data, though each row contains pairs of text (newcomers with their replies, subreddits with matched counterparts).

### Are there recommended data splits (e.g., training, development/validation, testing)?
The data are split by file, with `validation_data.csv` containing human-annotated labels, while the `gpt_4o_labels.csv` file (used for training) containing labels generated by GPT-4o.

### Are there any errors, sources of noise, or redundancies in the dataset?
There are none that we know of, though we encourage those who find errors to report them to the authors.

### Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)?
The text is self-contained, though metadata such as Reddit usernames are intentionally omitted to preserve user anonymity. The data contain IDs that can be used to access metadata, if users have downloaded the Pushshift dumps.

### Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctor-patient confidentiality, data that includes the content of individuals’ non-public communications)?
The data were obtained from publicly available Reddit comments.

### Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?
Yes. The dataset contains many instances of hate speech. Users should be cautious when viewing the dataset if they intend to avoid such speech.

### Does the dataset relate to people? 
Yes, the dataset is sourced from Reddit comments.

### Does the dataset identify any subpopulations (e.g., by age, gender)?
No.

### Is it possible to identify individuals (i.e., one or more natural persons), either directly or indirectly (i.e., in combination with other data) from the dataset?
Reddit users can be identified if the IDs are linked back to the full Pushshift dumps, though these usernames will often not identify individuals.

### Does the dataset contain data that might be considered sensitive in any way (e.g., data that reveals racial or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)?
Reddit users may have disclosed their religious beliefs, political opinions, or sexual orientations publicly within this dataset.

### Any other comments?

## Collection process

_\[T\]he answers to questions here may provide information that allow others to
reconstruct the dataset without access to it._

### How was the data associated with each instance acquired?
The data were acquired from (Pushshift)[https://ojs.aaai.org/index.php/ICWSM/article/view/7347]. The list of subreddits to sample from were obtained from prior research, as described above. For both the training and validation data, the comments were randomly sampled from each subreddit, with an equal number of comments coming from each subreddit. See the paper for more details on dataset construction.

### What mechanisms or procedures were used to collect the data (e.g., hardware apparatus or sensor, manual human curation, software program, software API)?

The data were collected and processed using Python and the Pandas library.

### If the dataset is a sample from a larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)?

Random sampling was used, stratified by subreddit.

### Who was involved in the data collection process (e.g., students, crowdworkers, contractors) and how were they compensated (e.g., how much were crowdworkers paid)?
Students and researchers annotated data for counterspeech/hate speech. They were not specifically compensated for this task.

### Over what timeframe was the data collected?
The Reddit comments were created between 2012 and the end of 2022. The data were processed/collected between the beginning of 2023 and the end of 2024.

### Were any ethical review processes conducted (e.g., by an institutional review board)?
No, collecting publicly available social media data is considered exempt by the institutional review board of our universities.

### Does the dataset relate to people?

_If not, you may skip the remainder of the questions in this section._

### Did you collect the data from the individuals in question directly, or obtain it via third parties or other sources (e.g., websites)?

### Were the individuals in question notified about the data collection?
No.

### Did the individuals in question consent to the collection and use of their data?
Users did not consent directly to their data being stored in Pushshift, though users had the option to opt-out of their data being stored in Pushshift.

### If consent was obtained, were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses?
N/A.

### Has an analysis of the potential impact of the dataset and its use on data subjects (e.g., a data protection impact analysis) been conducted?
None that we know of.

### Any other comments?

## Preprocessing/cleaning/labeling

_The questions in this section are intended to provide dataset consumers with the information
they need to determine whether the “raw” data has been processed in ways that are compatible
with their chosen tasks. For example, text that has been converted into a “bag-of-words” is
not suitable for tasks involving word order._

### Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)?
Yes, the comments were lightly processed to remove URLs and HTML entities.

### Was the “raw” data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)?
The raw data are not published on GitHub, though can be accessed from Pushshift.

### Is the software used to preprocess/clean/label the instances available?
Yes, the code is available in the `preprocessing.py` script of this repository.

### Any other comments?

## Uses

_These questions are intended to encourage dataset creators to reflect on the tasks
for which the dataset should and should not be used. By explicitly highlighting these tasks,
dataset creators can help dataset consumers to make informed decisions, thereby avoiding
potential risks or harms._

### Has the dataset been used for any tasks already?
Yes, the data have been used to train counterspeech detection models and analyze the impact of counterspeech on user retention in hate subreddits.

### Is there a repository that links to any or all papers or systems that use the dataset?
No.

### What (other) tasks could the dataset be used for?
Training other types of machine learning models, predicting which comments will receive counterspeech replies, and how users might respond to counterspeech replies.

### Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses?
If the counterspeech detection models are used to remove/moderate online content, it may unfairly censor certain groups due to unexpected biases in the model (e.g., the model may unfairly censor certain marginalized groups).

### Are there tasks for which the dataset should not be used?
The dataset is not intended to train models for generating text (other than classification labels), and such a use may be harmful due to the potential for such models to generate harmful speech. The dataset is also only intended to be used to analyze aggregate trends in hate speech/counterspeech.

### Any other comments?

## Distribution

### Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created? 
The dataset is made publicly available in this GitHub repository.

### How will the dataset will be distributed (e.g., tarball on website, API, GitHub)?
The data is available in this GitHub repository.

### When will the dataset be distributed?
The data are currently available.

### Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?
The associated repository is distributed under the MIT license, allowing any use of the code/dataset.

### Have any third parties imposed IP-based or other restrictions on the data associated with the instances?
No.

### Do any export controls or other regulatory restrictions apply to the dataset or to individual instances?
No.

### Any other comments?

## Maintenance

_These questions are intended to encourage dataset creators to plan for dataset maintenance
and communicate this plan with dataset consumers._

### Who is supporting/hosting/maintaining the dataset?
(Omitted for anonymity.)

### How can the owner/curator/manager of the dataset be contacted (e.g., email address)?
(Omitted for anonymity.)

### Is there an erratum?
No.

### Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete instances)?
If issues are identified in the datasets, they will be corrected and the GitHub repository will be updated.

### If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (e.g., were individuals in question told that their data would be retained for a fixed period of time and then deleted)?
N/A.

### Will older versions of the dataset continue to be supported/hosted/maintained?
This will depend on the nature of how the dataset may be updated in the future. If critical errors are found, the dataset will be updated and the old version will no longer be hosted. However, if there are cases where old versions remain trustworthy and useful, we will continue to host old versions.

### If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?
Yes, users can fork the GitHub repository and make their own changes.

### Any other comments?
